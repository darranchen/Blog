---
layout: post
title: R-台湾房地产资料分析案例
tagline: 2014台湾资料分析竞赛参赛总结
date: 2014-07-15
categories: Program
tags:  R Program
keywords:   R Program 资料分析
discription: 
---

   很有幸能在离开台湾之际跟我的小伙伴们参加由中华R软体研发暨应用协会和中国医药大学主办的2014 [台湾资料分析竞赛][compete]，简单讲一下这次的比赛的模式，这次比赛跟我们统计咨询的课很像，给一笔资料，然后自己根据这笔资料定一个目的，自己建立统计模型得到想要的讯息。我们详细上交的报告可以在我的github上面可以找到。 [report][]

   这次主办方提供的资料是68万的房地产资料，这是在开赛的时候才给我们的，比赛时间是上午9点到下午5点，要求对资料进行处理，作出一份完整的统计分析报告，初赛的书面报告占总分的80%， 决赛将初赛的结果上台报告，才占20%, 所以初赛的书面报告非常重要。本来以为主办方会给出一笔处理过的资料，然后给定目的以及目标变数之后，对于目标变数建模，谁知道这次主办方提供的资料是台湾政府的房屋交易实价登录系统的资料，这是台湾政府在2012年通过线上登录系统，这些资料都是用户直接登记的资料，现在在网上也可以直接下载到 [不动产资料][data]. 现在取得已经有70多万笔资料了，根据这笔资料，用户就能直接查询到自己想要交易的房屋类型的价格 [资料查询][search].

   这笔资料总共给了28个变数, 第一个是所属的县市，比如台北市，高雄市，第二个是交易的不动产类型， 有五种，土地, 建筑物，房地(建筑物+土地), 车位，以及 房地+车位。 另外还有详细的地址，总售价，建筑物转移总面积，土地总面积，交易横坐标，交易纵坐标等变数. 因为资料是没有处理过的，所以非常的乱，很多栏位都有Missing data, 而且会有不少的资料是乱填的，所以资料前处理是一个非常关键的因素，同时，主办方希望尽可能多的利用资料，因此又不能删除太多资料。

这次我们的队名是62531， 这是我们研究室的门牌号，介绍一下我们这一队的分工情况顺便介绍一下我的小伙伴，

* 陈庆全，本科是成大经济系，双主修统计，但是编程能力极强，写代码速度很快，脑袋瓜非常聪明，这次他负责的是资料前处理, 当别的组还是尝试用什么方法把主办方的资料读成比较方便处理的资料的时候，他在10分钟内已经将20多个csv档案读成方便处理的list了。这是最帅的庆全哥，有无数美女仰慕他，这真是让我们羡慕不已啊。而且他还因为我们研究室的小辰离开了，剃了他飘逸的长发，真是可歌可泣啊。

* 第二个是我们的核心,张惇皓，本科成大统计系直接上来读成大统研的，他是我现在接触到的同年龄里面统计最强的人，知道非常多奇奇怪怪的统计方法，这次也是他负责建立模型和结果解读.


* 蔡琬慈， 惇皓的女朋友，也是成大统计出来的，据说本科是他们班前几名的，很聪明，这里面她负责的部分是报告的编辑。 

* 唐志扬，当年台大流病所研究所招生第一名，不过后来还是留在成大统研，比我们小一届，这次他和琬慈一起负责的是报告，还有一开始资料的探索性图形呈现。

* 而我在这里面扮演的角色也是我自己希望的角色，就是扮演好在资料前处理的偏计算机的人与统计模型建立的统计专家之间的衔接角色。在资料前处理的时候，对于房地产交易年月, 需要把年月分开提取出来,与庆全一起讨论将数字变为字符串的形式，直接读取字符串再转为数字这种方式，在模型建立的时候和惇皓一起，负责最传统的线性回归，建立基本模型，这个时候也能知道惇皓的建模流程，因此，最后当惇皓在写模型选择那一章节的时候，我也同时在编写结论，这样节省了不少时间。

9:00 开始拿到资料，一开始需要确定我们的目标是什么, 虽然时间非常有限，但是目的决定了我们后面资料处理的难易度，需要根据资料来决定，因此我们分成三个小组，每个小组负责大概10个变数，整理每个变数缺失值的比例，有多少类，每一类的个数是多少，然后自己考虑有什么可行的目的，10:00 讨论决定目的。

10:00- 14:00 决定了我们只针对有建筑物的房屋资料(建筑物，房地，房地+车位)这三种类型的资料，总共有47万笔资料，因为纯土地，或者纯车位的交易方式实际上跟有建筑物的房屋有很大不同，要用同一个模型去描述它们是比较不合理的，给需要购买房屋的用户提供一个房屋每平方米价格的模型。用户可以根据房屋所在的县市，建筑总面积，房间个数，厅数，厕所数等情况得到房屋的大致价格数目. 那么目标变数确定为房屋每平方米。那么需要模型需要包括哪些变数是会对我们关心的每平方米单价有影响的。 这个时候就是数据分析第一步，Model-free Graphic. 然后庆全，惇皓和我就开始考虑哪些有意义，而琬慈和志扬就将刚刚的目的写入报告中。 最终我们确定了17个对于目标变数有影响的变数，用他们建模型。 11:00 - 12:00 其中我被这里面的 交易纵坐标和交易横坐标这两个变数吸引了，这两个值是根据用户的地址直接产生出交易房屋的价格的，这个时候我就想根据这个坐标对于我们样本点做权重，比如要买台北市大安区的一个房子，那么价格主要就是参照在附近的已交易的房子，距离越近，权重越大，这个想法很直观，跟我们平时买房子一样的，要买一个地方的房子，就是看周围两边的房子的价格是多少。 这个想法可以考虑用distance based linear regression 实现，跟惇皓交流完之后，刚好他们去吃饭的空余时间，惇皓就将这两个交易坐标轴画成heat map，发现交易点太稀疏了，因此可能估计不出东西，另外从时间的角度考虑，可能没有时间做这么复杂的模型，所以就先做我们一开始定的模型log-linear model.

14:00 - 16:00 建模，庆全处理完资料之后，我们开始使用资料建模，在庆全处理资料的时候，我们已经讲基本模型做好，只需要庆全把资料拿过来就可以开始建模了，这里我们用log-linear model. 为什么要做log转换，庆全的讲法是价格的资料一般都会左偏，而惇皓的解释是价格资料它的影响因素从物理上面是乘积得到的，比如多一个房间，那么价格大概多1.5倍，那么使用log转换的话，就可以用linear model的方式加起来了，这个解释我比较赞同的。对于这17个变数，建立log-linear model之后就需要做估计了，我负责 Ordinary least square 的估计方式，惇皓负责 Lasso 和Group Lasso 的估计方法，Ordinary least square 是要做回归首先要做的，这里把17个变数放进去之后，发现资料变异的解释量 $ R^2 $ 达到了 61\%, 顿时觉得信心来了，这样的解释变异对于47万笔资料而言已经是非常好的了，因为这是大资料，所以如果是看传统的变数系数的显著性的话，一般资料多系数都会显著不为0，所以几乎每个变数都显著，那么这里就是用 stepAIC 去选择，stepAIC 是去看少掉一个变数会不会让它的AIC值变大很多，如果不变，那么这个变数就不重要，如果变大了，那么这个变数就需要包括进来，看看是否可以删除一些不重要的变数，这里结果竟然所有变数都重要。这里有可能因为资料的残差并没有符合常态的假设，因为AIC也是同时假设了残差是服从常态的，当样本数变多的时候，有时候常态经常不能满足，这就是悲剧啊。 这个时候就是惇皓的Group Lasso派上用场了，Lasso 是根据cross validation error 的大小这样来选择重要变数的，通过改变penality term $\lambda$ 选择使cross validation error 最小的lambda 值， 同时有可以剔除不重要变数， 这里相比于 Lasso而选择Group Lasso, 这是为了弥补Lasso 的缺陷， 当我们的资料里面有高度相关的共变数的时候，Lasso会倾向于只选择其中的一个变数，而不会全部都选择，即使其中的变数确实对于目标变数有影响也不会被选入。 这个问题对于类别型变数有天生的影响，因为类别型变数建模的时候使用dummy variable, 可想而知，如果一个有3个不同level的类别型变数，会产生2个dummy variable, 这两个变数是高度相关的， 那么很有可能这两个变数里面只选择了一个变数，这个非常不合理，因为最后的模型只有类别型变数的其中一个或两个level， 而不是全部都有。 Group Lasso 这里就是把高度相关的变数合为一个 Group, 在剔除变数的时候是以Group 为单位，而不是以一个变数为单位， 所以对类别型变数直接将所有dummy valiable 和为一个group，这样就不会担心只删除一个或者两个了。 而因为我们资料里面类别型资料比较多，因此使用Group Lasso比Lasso会更适合。最终使用Group Lasso 删除了三个变数，第一个是土地转移总面积，二个是房间个数,三个有无管理组织被删去了。同时，我们使用10 fold Cross Validation 去比较两个模型，发现MSE几乎差不多，那么就选择了Group Lasso. 这个时候庆全，琬慈，志扬开始打资料前处理的报告，以及基本的模型，还有画Model-free 的图。

16:00- 17:00 将模型的结果放入表格中，解释文中的结果，整理R 代码，加上注释，上交，完成。八小时后，整个人都呆了。


7月19号去参加决赛，最终得到了佳作(第五名), 做得不好的需要总结一下， 一. 在做资料前处理的过程中没有加多一个验证环节, 使得后面在建模型的时候又发现错了，需要回去做修改。花了很多时间。 二. 这次比赛太注重方法的准确性，而少了对于实际资料的得到的结果的解读，在实际上的应用。 三. 撰写报告的时间安排太少了，需要把书面报告编辑得更好，这次就是时间上面安排不及。 讲一下做的好的点， 首先，方法的选择和使用比较准确，这次进入决赛的清华2组以及其他一些学校的有跟我们一样做房价预测模型的，口头报告的时候我们组对于模型的使用以及缺陷的理解比其他组好很多， 在做房价预估模型里面我们组最后得到的名次最高。 第二个就是无论初赛和决赛都很认真去对待， 尤其是决赛的口头报告，报告的逻辑很严谨。 最终当天宣布结果的以后，辅仁大学统计系的系主任转过来跟我们说:“ 她非常欣赏我们组，只是我们组在初赛报告的实际应用写太少了。" 我们晚上搭车会台南的时候，清华那一组还发短信跟惇皓讲，他们清华的人觉得口头报告完第一名会是我们组。 注意以后还是要把东西包装好。


这次学到很多东西，庆全对于资料前处理的时候写处理代码非常有效率，主要用到的也是他之前有写过的代码，直接参考一下就可以了，在这个blog里面我也想保持比较多我写过的code，这样使用起来很快。还有惇皓对于各种方法的理解以及在R上面的实现，有了想法之后可以直接在R上面验证这个想法是否可行，确实，如果想要成为某个领域的专家，需要花在这上面的时间要超过10000小时，后续继续学习和努力。
后续继续学习和努力

[compete]: http://www.carra.org.tw/dm/
[report]: https://github.com/darranchen/Blog/blob/gh-pages/_posts/Program/Household/R1399955006.pdf
[data]: http://plvr.land.moi.gov.tw/DownloadOpenData
[search]: http://lvr.land.moi.gov.tw/N11/changemenu.action#map
[gambler]: http://en.wikipedia.org/wiki/Gambler%27s_ruin
[nplayer]: http://www.sciencedirect.com/science/article/pii/S0196885804000363
[holdem]: http://en.wikipedia.org/wiki/Texas_hold_%27em
[branch]: http://blog.xjchen.net/book/2014/04/30/git3/
<!-- []: {{BASE_PATH}}/images/a.png -->
<!-- {%highlight html%} {%endhighlight%}-->

