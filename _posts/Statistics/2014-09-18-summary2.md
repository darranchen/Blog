---
layout: post
title: "统计复习资料总结(2)"
date: 2014-09-18 23:34:00
categories: Statistics
tags: 统计
keywords: 统计 
---

数据分析模型的分类，一般分为监督(supervise)与非监督(unsupervise),这里的意思是有反应变数y和没有反应变数y. 反应变数y又会被分成 连续型的和类别型的。连续型的就是可以考虑用正常的线性模型linear model, 或者GLM做。这里主要是做类别型的资料，有

1. 逻辑式回归
2. 神经网络
3. SVM
4. 决策树

# 逻辑式回归

逻辑式回归的概念首先需要从线性回归讲起,线性回归的表达式

$$ E(y|x) = x\beta $$

在这个等式下面 E(y|x)的取值范围是从 $(-\infty, \infty)$, 我们这里是用于分类就是response不是0就是1， 那么我们现在做一个 想做逻辑式的转换logit(E(y|x))，让取值范围在(0,1) 之间，这样我们就能够给定一个阀值用于确定到底需要将这个值判断为0，还是判断为1. 那么logit转换其实就是做了

$$ y= \frac{1}{1+e^{-x\beta}} $$

这样的转换，那么y的取值就会在 (0,1)之间了。 这里的阀值a是什么概念，这里的阀值就是可以定义当给定 $x_0$ 得到的结果是 $y_0$的时候，如果 $y_0> a$ 则是判断为1类，如果小于a 就判断为0类。 那么这个阀值怎么做选择， 选择的方式其实是你觉得哪一个错误比较严重而定的。 我们真实看到的值有0和1两类， 在判断的时候就会有2类，那么会有四种情况发生

1. true positive 也就是正确的判断为对的(tp)
2. false positive 也就是错误的判断为对的，把负类判断为正类的个数(fp)
3. false negative 也就是错误的判断为负的，把正类判断为负类的个数(fn)
4. true negative 正确的判断为负的(tn)

这个时候对应的概念就来了，我们希望 tp 和tn 两个同时越大越好，那么对于同一种方法的话，我们就会选择做一个权衡,首先定义了

$Recall = \frac{tp}{tp+fn}$ 就是正确被判断为正占所有正的的比例。也就是正的覆盖率, Sensitivity

$Specificity = \frac{tn}{tn+ft}$ 这个是正确被判断为负的占所有正的比例。

$Precision = \frac{tp}{tp+fp}$ 这个是正确被判断为正占被判断为正的比例。

我们希望 R 和P 同时足够大，那么就定义一个指标做 

$$  F = \frac{(w^2+1)P*R}{w^2(P+R)}$$

简化版的 

$$ F_1 = \frac{2}{\frac{1}{P}+\frac{1}{R}} = \frac{2PR}{P+R}$$

在选择阀值的之后可以使 $F_1$ 最大。 当我们有多个不同方法做比较的时候，其实就这个时候只是比较 $F_1$的时候会有一些不公平，这个时候就引入了ROC曲线。 ROC曲线其实在比较一个东西， 横坐标是 Specificity,纵坐标是 Sensitivity, 这样就可以把同时去看在不同阀值下面Specificity 和Sensitive的情况如何了。

## 逻辑式回归的优缺点

逻辑式回归和线性回归有同样的优点，就是1. 简单方便。 除此之外还有同样样本模型，结果是唯一的。缺点其实就是，它描述的是一个线性的关系，如果真实的是非线性的关系，那么这种情况就无法准确描述了。 



[Rblog]: http://www.r-bloggers.com "R-bloggers"
[sim]: http://www.r-bloggers.com/simpsos-paradox-is-back/
